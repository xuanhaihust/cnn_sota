{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Conv2D, MaxPool2D, Dense\n",
    "from keras.layers import BatchNormalization, Dropout, Flatten\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This implementation use Batch Normalization (BN) instead of Local Response Normalization (LRN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 54, 54, 96)        34944     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 54, 54, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 26, 26, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 26, 26, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 26, 26, 256)       614656    \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 26, 26, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 12, 12, 384)       885120    \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 12, 12, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 12, 12, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 12, 12, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 12, 12, 256)       884992    \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4096)              26218496  \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 50,845,416\n",
      "Trainable params: 50,844,712\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate an empty sequential model\n",
    "model = Sequential()\n",
    "# 1st layer (conv + pool + batchnorm)\n",
    "model.add(Conv2D(filters= 96, kernel_size= (11,11), strides=(4,4), padding='valid', input_shape = (224,224,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(3,3), strides=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 2nd layer (conv + pool + batchnorm)\n",
    "model.add(Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='same', kernel_regularizer=l2(5e-4)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(3,3), strides=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "        \n",
    "# layer 3 (conv + batchnorm)      <--- note that the authors did not add a POOL layer here\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same', kernel_regularizer=l2(5e-4)))\n",
    "model.add(Activation('relu'))\n",
    "    \n",
    "# layer 4 (conv + batchnorm)     <--- similar to layer 4\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same', kernel_regularizer=l2(5e-4)))\n",
    "model.add(Activation('relu'))\n",
    "        \n",
    "# layer 5 (conv + batchnorm) \n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same', kernel_regularizer=l2(5e-4)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(3,3), strides=(2,2)))\n",
    "\n",
    "# Flatten the CNN output to feed it with fully connected layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# layer 6 (Dense layer + dropout) \n",
    "model.add(Dense(units = 4096, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# layer 7 (Dense layers)\n",
    "model.add(Dense(units = 4096, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "                        \n",
    "# layer 8 (softmax output layer)\n",
    "model.add(Dense(units = 1000, activation = 'softmax'))\n",
    "\n",
    "# print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-72ee380f9385>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# call the reduce_lr value using callbacks in the training method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m model.fit(X_train, y_train, batch_size=128, epochs=90, validation_data=(X_test, y_test),\n\u001b[0m\u001b[0;32m     13\u001b[0m        verbose=2, callbacks=[reduce_lr])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# reduce learning rate by 0.1 when the validation error plateaus\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1))\n",
    "\n",
    "# set the SGD optimizer with lr of 0.01 and momentum of 0.9\n",
    "optimizer = keras.optimizers.sgd(lr = 0.01, momentum = 0.9)\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "# call the reduce_lr value using callbacks in the training method\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=90, validation_data=(X_test, y_test),\n",
    "       verbose=2, callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('cv_venv': venv)",
   "language": "python",
   "name": "python37664bitcvvenvvenv3609f0dd452f433796cff491973b96d7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
